{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist, cifar10, cifar100\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder structure\n",
    "BASE_DIR = \"saved_models\"\n",
    "PLOT_DIR = \"training_graphs\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom activation functions\n",
    "def penalized_tanh(x, alpha=0.25):  # alpha is a hyperparameter (default 0.25)\n",
    "    return tf.where(x >= 0, tf.tanh(x), alpha * tf.tanh(x))\n",
    "\n",
    "def eliSH(x):\n",
    "    return x * tf.nn.sigmoid(x) * (1 + tf.nn.tanh(x))\n",
    "\n",
    "def mish(x):\n",
    "    return x * tf.nn.tanh(K.softplus(x))  # softplus(x) = log(1 + exp(x))\n",
    "\n",
    "def rsigelu(x):\n",
    "    return x * tf.nn.sigmoid(x) + tf.nn.elu(x)\n",
    "\n",
    "def tanh_exp(x):\n",
    "    return x * tf.tanh(K.exp(x))\n",
    "\n",
    "def pflu(x, alpha=0.1, beta=1.0):\n",
    "    return tf.where(x >= 0, x + beta, alpha * (tf.exp(x) - 1))\n",
    "\n",
    "def gcu(x):\n",
    "    return x * tf.cos(x)\n",
    "\n",
    "def hcLSH(x):\n",
    "    return x * tf.nn.sigmoid(x) * K.log(K.sigmoid(x) + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = {\n",
    "    \"relu\": tf.nn.relu,\n",
    "    \"tanh\": tf.nn.tanh,\n",
    "    \"sigmoid\": tf.nn.sigmoid,\n",
    "    \"hcLSH\": hcLSH,\n",
    "    \"penalized_tanh\": penalized_tanh,\n",
    "    \"eliSH\": eliSH,\n",
    "    \"mish\": mish,\n",
    "    \"rsigelu\": rsigelu,\n",
    "    \"tanh_exp\": tanh_exp,\n",
    "    \"pflu\": pflu,\n",
    "    \"gcu\": gcu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_colors = {\n",
    "    \"relu\": \"blue\",\n",
    "    \"tanh\": \"green\",\n",
    "    \"sigmoid\": \"red\",\n",
    "    \"hcLSH\": \"purple\",\n",
    "    \"penalized_tanh\": \"orange\",\n",
    "    \"eliSH\": \"cyan\",\n",
    "    \"mish\": \"magenta\",\n",
    "    \"rsigelu\": \"brown\",\n",
    "    \"tanh_exp\": \"pink\",\n",
    "    \"pflu\": \"gray\",\n",
    "    \"gcu\": \"olive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn():\n",
    "    train_data = loadmat(\"path/to/train_32x32.mat\")\n",
    "    test_data = loadmat(\"path/to/test_32x32.mat\")\n",
    "\n",
    "    X_train = np.moveaxis(train_data[\"X\"], -1, 0)  # Move axis to match TF format\n",
    "    y_train = train_data[\"y\"].flatten() % 10  # Normalize labels (SVHN uses 1-10)\n",
    "    \n",
    "    X_test = np.moveaxis(test_data[\"X\"], -1, 0)\n",
    "    y_test = test_data[\"y\"].flatten() % 10\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    if dataset_name == \"fashion_mnist\":\n",
    "        (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "        X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
    "        X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    elif dataset_name == \"cifar10\":\n",
    "        (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    elif dataset_name == \"cifar100\":\n",
    "        (X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "\n",
    "    elif dataset_name == \"svhn\":\n",
    "        X_train, X_test, y_train, y_test = load_svhn()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Dataset not supported!\")\n",
    "\n",
    "    # Normalize data\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, activation_name, num_classes):\n",
    "    activation_func = activation_functions[activation_name]\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", input_shape=input_shape),\n",
    "        Lambda(activation_func),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\"),\n",
    "        Lambda(activation_func),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(256),\n",
    "        Lambda(activation_func),\n",
    "        Dropout(0.1),\n",
    "        Dense(128),\n",
    "        Lambda(activation_func),\n",
    "        Dropout(0.1),\n",
    "        Dense(num_classes, activation=\"softmax\")  # Multi-class classification\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(activation_name, input_shape, num_classes):\n",
    "    activation_fn = activation_functions[activation_name]  # Default to Tanh if not found\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.SimpleRNN(64, activation=activation_fn, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.SimpleRNN(128, activation=activation_fn, return_sequences=False),\n",
    "        tf.keras.layers.Dense(64, activation=activation_fn),\n",
    "        tf.keras.layers.Dense(128, activation=activation_fn),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")  # Output layer\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save model properly\n",
    "def save_model(model, dataset_name, activation_name):\n",
    "    model_dir = os.path.join(\"saved_models\", dataset_name)\n",
    "    os.makedirs(model_dir, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "    # Save model weights (only weights, NOT full model)\n",
    "    model_path = os.path.join(model_dir, f\"cnn_{dataset_name}_{activation_name}.h5\")\n",
    "    model.save_weights(model_path)  # Save weights\n",
    "    print(f\"✅ Model weights saved: {model_path}\")\n",
    "\n",
    "    # Save metadata separately (since model structure cannot be serialized)\n",
    "    metadata = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"activation\": activation_name,\n",
    "    }\n",
    "    metadata_path = os.path.join(model_dir, f\"metadata_{dataset_name}_{activation_name}.json\")\n",
    "    with open(metadata_path, \"w\") as json_file:\n",
    "        json.dump(metadata, json_file, indent=4)\n",
    "\n",
    "    print(f\"✅ Metadata saved: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reload the model\n",
    "def load_saved_model(dataset_name, activation_name, input_shape, num_classes):\n",
    "    model_dir = os.path.join(\"saved_models\", dataset_name)\n",
    "\n",
    "    # Rebuild the model\n",
    "    model = create_cnn_model(input_shape, activation_name, num_classes)\n",
    "\n",
    "    # Load saved weights\n",
    "    model_path = os.path.join(model_dir, f\"cnn_{dataset_name}_{activation_name}.h5\")\n",
    "    model.load_weights(model_path)\n",
    "    print(f\"✅ Model weights loaded: {model_path}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training results\n",
    "def plot_training(history, dataset_name, activation_name):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Accuracy Plot\n",
    "    ax[0].plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    ax[0].plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    ax[0].set_title(f\"Accuracy ({dataset_name}, {activation_name})\")\n",
    "    ax[0].set_xlabel(\"Epochs\")\n",
    "    ax[0].set_ylabel(\"Accuracy\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Loss Plot\n",
    "    ax[1].plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    ax[1].plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    ax[1].set_title(f\"Loss ({dataset_name}, {activation_name})\")\n",
    "    ax[1].set_xlabel(\"Epochs\")\n",
    "    ax[1].set_ylabel(\"Loss\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    # Save plot\n",
    "    plot_filename = f\"{PLOT_DIR}/training_{dataset_name}_{activation_name}.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "    print(f\"📊 Plot saved as {plot_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save test results per dataset\n",
    "def save_test_results(dataset_name, activation_name, test_loss, test_acc):\n",
    "    results_file = os.path.join(RESULTS_DIR, f\"{dataset_name}_results.csv\")\n",
    "    \n",
    "    file_exists = os.path.isfile(results_file)\n",
    "\n",
    "    with open(results_file, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Activation Function\", \"Test Loss\", \"Test Accuracy\"])  # Header\n",
    "        writer.writerow([activation_name, test_loss, test_acc])  # Write results\n",
    "    \n",
    "    print(f\"✅ Test accuracy saved in {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training on fashion_mnist with activation: relu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_38 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_76 (Lambda)          (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_77 (Lambda)          (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_78 (Lambda)          (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_79 (Lambda)          (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:06:47.950739: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 12s 12ms/step - loss: 0.6190 - accuracy: 0.7996 - val_loss: 0.5280 - val_accuracy: 0.8391\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_relu.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_relu.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_relu.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5280 - accuracy: 0.8391\n",
      "📊 Test Accuracy on fashion_mnist with relu: 0.8391\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_80 (Lambda)          (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_81 (Lambda)          (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_82 (Lambda)          (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_83 (Lambda)          (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.4068 - accuracy: 0.8522 - val_loss: 0.3067 - val_accuracy: 0.8891\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_tanh.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_tanh.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_tanh.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3067 - accuracy: 0.8891\n",
      "📊 Test Accuracy on fashion_mnist with tanh: 0.8891\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_42 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_84 (Lambda)          (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_85 (Lambda)          (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_86 (Lambda)          (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_87 (Lambda)          (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 1.1217 - accuracy: 0.5781 - val_loss: 0.5535 - val_accuracy: 0.7961\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_sigmoid.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_sigmoid.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_sigmoid.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5535 - accuracy: 0.7961\n",
      "📊 Test Accuracy on fashion_mnist with sigmoid: 0.7961\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: hcLSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_44 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_88 (Lambda)          (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_44 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_89 (Lambda)          (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_45 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_90 (Lambda)          (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_91 (Lambda)          (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 16s 16ms/step - loss: 0.5251 - accuracy: 0.8094 - val_loss: 0.3591 - val_accuracy: 0.8693\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_hcLSH.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_hcLSH.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_hcLSH.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3591 - accuracy: 0.8693\n",
      "📊 Test Accuracy on fashion_mnist with hcLSH: 0.8693\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: penalized_tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_46 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_92 (Lambda)          (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_46 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_93 (Lambda)          (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_94 (Lambda)          (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_95 (Lambda)          (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:07:49.199670: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4252 - accuracy: 0.8456 - val_loss: 0.3087 - val_accuracy: 0.8880\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_penalized_tanh.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_penalized_tanh.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_penalized_tanh.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3087 - accuracy: 0.8880\n",
      "📊 Test Accuracy on fashion_mnist with penalized_tanh: 0.8880\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: eliSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_96 (Lambda)          (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_97 (Lambda)          (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_98 (Lambda)          (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_99 (Lambda)          (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 16s 16ms/step - loss: 0.4315 - accuracy: 0.8444 - val_loss: 0.3083 - val_accuracy: 0.8878\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_eliSH.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_eliSH.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_eliSH.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3083 - accuracy: 0.8878\n",
      "📊 Test Accuracy on fashion_mnist with eliSH: 0.8878\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: mish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_50 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_100 (Lambda)         (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_101 (Lambda)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_102 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_103 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 23s 23ms/step - loss: 0.4362 - accuracy: 0.8401 - val_loss: 0.3381 - val_accuracy: 0.8759\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_mish.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_mish.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_mish.png\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3381 - accuracy: 0.8759\n",
      "📊 Test Accuracy on fashion_mnist with mish: 0.8759\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: rsigelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_52 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_104 (Lambda)         (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_105 (Lambda)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_106 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_107 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:08:51.036892: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 28s 29ms/step - loss: 0.3855 - accuracy: 0.8611 - val_loss: 0.3442 - val_accuracy: 0.8716\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_rsigelu.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_rsigelu.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_rsigelu.png\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3442 - accuracy: 0.8716\n",
      "📊 Test Accuracy on fashion_mnist with rsigelu: 0.8716\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: tanh_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_108 (Lambda)         (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_109 (Lambda)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_110 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_111 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4080 - accuracy: 0.8514 - val_loss: 0.3089 - val_accuracy: 0.8868\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_tanh_exp.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_tanh_exp.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_tanh_exp.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3089 - accuracy: 0.8868\n",
      "📊 Test Accuracy on fashion_mnist with tanh_exp: 0.8868\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on fashion_mnist with activation: gcu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_56 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " lambda_112 (Lambda)         (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " lambda_113 (Lambda)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 256)               803072    \n",
      "                                                                 \n",
      " lambda_114 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_115 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 856074 (3.27 MB)\n",
      "Trainable params: 856074 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.3910 - accuracy: 0.8607 - val_loss: 0.3368 - val_accuracy: 0.8751\n",
      "✅ Model weights saved: saved_models/fashion_mnist/cnn_fashion_mnist_gcu.h5\n",
      "✅ Metadata saved: saved_models/fashion_mnist/metadata_fashion_mnist_gcu.json\n",
      "📊 Plot saved as training_graphs/training_fashion_mnist_gcu.png\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3368 - accuracy: 0.8751\n",
      "📊 Test Accuracy on fashion_mnist with gcu: 0.8751\n",
      "✅ Test accuracy saved in results/fashion_mnist_results.csv\n",
      "🔹 Training on cifar10 with activation: relu\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 36s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_58 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_116 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_117 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_118 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_119 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:10:49.802849: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 14ms/step - loss: 1.7660 - accuracy: 0.3884 - val_loss: 1.5320 - val_accuracy: 0.4869\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_relu.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_relu.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_relu.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.5320 - accuracy: 0.4869\n",
      "📊 Test Accuracy on cifar10 with relu: 0.4869\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_120 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_121 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_122 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_123 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 1.3689 - accuracy: 0.5151 - val_loss: 1.1291 - val_accuracy: 0.6008\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_tanh.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_tanh.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_tanh.png\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.1291 - accuracy: 0.6008\n",
      "📊 Test Accuracy on cifar10 with tanh: 0.6008\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_62 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_124 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_62 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_125 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_63 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_126 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_127 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 11s 13ms/step - loss: 2.3150 - accuracy: 0.1017 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_sigmoid.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_sigmoid.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_sigmoid.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.3043 - accuracy: 0.1000\n",
      "📊 Test Accuracy on cifar10 with sigmoid: 0.1000\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: hcLSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_64 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_128 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_129 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_130 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_131 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 1.5571 - accuracy: 0.4365 - val_loss: 1.2630 - val_accuracy: 0.5431\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_hcLSH.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_hcLSH.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_hcLSH.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2630 - accuracy: 0.5431\n",
      "📊 Test Accuracy on cifar10 with hcLSH: 0.5431\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: penalized_tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_66 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_132 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_133 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_134 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_135 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:11:54.087500: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 13s 16ms/step - loss: 1.3424 - accuracy: 0.5163 - val_loss: 1.0490 - val_accuracy: 0.6344\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_penalized_tanh.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_penalized_tanh.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_penalized_tanh.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.0490 - accuracy: 0.6344\n",
      "📊 Test Accuracy on cifar10 with penalized_tanh: 0.6344\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: eliSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_68 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_136 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_137 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_138 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_139 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 15s 18ms/step - loss: 1.3917 - accuracy: 0.5028 - val_loss: 1.0983 - val_accuracy: 0.6128\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_eliSH.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_eliSH.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_eliSH.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.0983 - accuracy: 0.6128\n",
      "📊 Test Accuracy on cifar10 with eliSH: 0.6128\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: mish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_70 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_140 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_70 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_141 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_71 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_142 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_143 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 19s 23ms/step - loss: 1.3889 - accuracy: 0.5022 - val_loss: 1.0960 - val_accuracy: 0.6124\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_mish.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_mish.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_mish.png\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 1.0960 - accuracy: 0.6124\n",
      "📊 Test Accuracy on cifar10 with mish: 0.6124\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: rsigelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_72 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_144 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_145 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_146 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_147 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:12:56.551512: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 24s 29ms/step - loss: 1.4365 - accuracy: 0.5090 - val_loss: 1.1055 - val_accuracy: 0.6063\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_rsigelu.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_rsigelu.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_rsigelu.png\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 1.1055 - accuracy: 0.6063\n",
      "📊 Test Accuracy on cifar10 with rsigelu: 0.6063\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: tanh_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_74 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_148 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_149 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_150 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_151 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 1.3406 - accuracy: 0.5205 - val_loss: 1.0310 - val_accuracy: 0.6381\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_tanh_exp.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_tanh_exp.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_tanh_exp.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.0310 - accuracy: 0.6381\n",
      "📊 Test Accuracy on cifar10 with tanh_exp: 0.6381\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar10 with activation: gcu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_76 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_152 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_153 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_154 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_155 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1102410 (4.21 MB)\n",
      "Trainable params: 1102410 (4.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 1.3841 - accuracy: 0.5075 - val_loss: 1.0671 - val_accuracy: 0.6236\n",
      "✅ Model weights saved: saved_models/cifar10/cnn_cifar10_gcu.h5\n",
      "✅ Metadata saved: saved_models/cifar10/metadata_cifar10_gcu.json\n",
      "📊 Plot saved as training_graphs/training_cifar10_gcu.png\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.0671 - accuracy: 0.6236\n",
      "📊 Test Accuracy on cifar10 with gcu: 0.6236\n",
      "✅ Test accuracy saved in results/cifar10_results.csv\n",
      "🔹 Training on cifar100 with activation: relu\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 48s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_78 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_156 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_157 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_158 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_159 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:15:01.390749: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 13ms/step - loss: 5.0681 - accuracy: 0.0460 - val_loss: 4.0457 - val_accuracy: 0.1151\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_relu.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_relu.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_relu.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 4.0457 - accuracy: 0.1151\n",
      "📊 Test Accuracy on cifar100 with relu: 0.1151\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_80 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_160 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_161 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_162 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_163 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 11s 13ms/step - loss: 3.5728 - accuracy: 0.1674 - val_loss: 3.1070 - val_accuracy: 0.2498\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_tanh.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_tanh.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_tanh.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.1070 - accuracy: 0.2498\n",
      "📊 Test Accuracy on cifar100 with tanh: 0.2498\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_82 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_164 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_165 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_166 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_167 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 11s 14ms/step - loss: 4.6146 - accuracy: 0.0091 - val_loss: 4.6057 - val_accuracy: 0.0100\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_sigmoid.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_sigmoid.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_sigmoid.png\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 4.6057 - accuracy: 0.0100\n",
      "📊 Test Accuracy on cifar100 with sigmoid: 0.0100\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: hcLSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_84 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_168 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_84 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_169 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_85 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_170 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_171 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 3.8814 - accuracy: 0.1127 - val_loss: 3.4590 - val_accuracy: 0.1891\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_hcLSH.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_hcLSH.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_hcLSH.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.4590 - accuracy: 0.1891\n",
      "📊 Test Accuracy on cifar100 with hcLSH: 0.1891\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: penalized_tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_86 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_172 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_87 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_173 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_174 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_86 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_175 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:16:12.188924: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 17ms/step - loss: 3.6705 - accuracy: 0.1451 - val_loss: 3.2023 - val_accuracy: 0.2228\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_penalized_tanh.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_penalized_tanh.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_penalized_tanh.png\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 3.2023 - accuracy: 0.2228\n",
      "📊 Test Accuracy on cifar100 with penalized_tanh: 0.2228\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: eliSH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_88 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_176 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_89 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_177 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_44 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_178 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_179 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 14s 17ms/step - loss: 3.5672 - accuracy: 0.1662 - val_loss: 2.9859 - val_accuracy: 0.2654\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_eliSH.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_eliSH.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_eliSH.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.9859 - accuracy: 0.2654\n",
      "📊 Test Accuracy on cifar100 with eliSH: 0.2654\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: mish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_90 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_180 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_181 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_182 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_183 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 24s 29ms/step - loss: 3.5539 - accuracy: 0.1660 - val_loss: 2.9896 - val_accuracy: 0.2677\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_mish.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_mish.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_mish.png\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 2.9896 - accuracy: 0.2677\n",
      "📊 Test Accuracy on cifar100 with mish: 0.2677\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: rsigelu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_92 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_184 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_92 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_185 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_93 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_186 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_187 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:17:21.714725: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 32s 40ms/step - loss: 3.4982 - accuracy: 0.1860 - val_loss: 2.8507 - val_accuracy: 0.2975\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_rsigelu.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_rsigelu.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_rsigelu.png\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 2.8507 - accuracy: 0.2975\n",
      "📊 Test Accuracy on cifar100 with rsigelu: 0.2975\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: tanh_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_94 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_188 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_94 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_189 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_190 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_191 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 15s 18ms/step - loss: 3.5004 - accuracy: 0.1753 - val_loss: 2.9406 - val_accuracy: 0.2773\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_tanh_exp.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_tanh_exp.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_tanh_exp.png\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.9406 - accuracy: 0.2773\n",
      "📊 Test Accuracy on cifar100 with tanh_exp: 0.2773\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n",
      "🔹 Training on cifar100 with activation: gcu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_96 (Conv2D)          (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " lambda_192 (Lambda)         (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " lambda_193 (Lambda)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_48 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 256)               1048832   \n",
      "                                                                 \n",
      " lambda_194 (Lambda)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " lambda_195 (Lambda)         (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 100)               12900     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1114020 (4.25 MB)\n",
      "Trainable params: 1114020 (4.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "782/782 [==============================] - 23s 29ms/step - loss: 3.6832 - accuracy: 0.1554 - val_loss: 3.1616 - val_accuracy: 0.2437\n",
      "✅ Model weights saved: saved_models/cifar100/cnn_cifar100_gcu.h5\n",
      "✅ Metadata saved: saved_models/cifar100/metadata_cifar100_gcu.json\n",
      "📊 Plot saved as training_graphs/training_cifar100_gcu.png\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 3.1616 - accuracy: 0.2437\n",
      "📊 Test Accuracy on cifar100 with gcu: 0.2437\n",
      "✅ Test accuracy saved in results/cifar100_results.csv\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"fashion_mnist\", \"cifar10\", \"cifar100\"]  # Change to \"cifar10\", \"cifar100\", \"svhn\"\n",
    "activation_functions = {\n",
    "    \"relu\": tf.nn.relu,\n",
    "    \"tanh\": tf.nn.tanh,\n",
    "    \"sigmoid\": tf.nn.sigmoid,\n",
    "    \"hcLSH\": hcLSH,\n",
    "    \"penalized_tanh\": penalized_tanh,\n",
    "    \"eliSH\": eliSH,\n",
    "    \"mish\": mish,\n",
    "    \"rsigelu\": rsigelu,\n",
    "    \"tanh_exp\": tanh_exp,\n",
    "    \"gcu\": gcu\n",
    "}\n",
    "for dataset in datasets:\n",
    "        for activation in activation_functions:\n",
    "            print(f\"🔹 Training on {dataset} with activation: {activation}\")\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = load_dataset(dataset)\n",
    "            num_classes = len(np.unique(y_train))\n",
    "            \n",
    "            model = create_cnn_model(X_train.shape[1:], activation, num_classes)\n",
    "            model.summary()\n",
    "            \n",
    "            history=model.fit(X_train, y_train, epochs=1, batch_size=64, validation_data=(X_test, y_test))\n",
    "            \n",
    "            save_model(model, dataset, activation)\n",
    "            plot_training(history, dataset, activation)\n",
    "            \n",
    "            test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "            print(f\"📊 Test Accuracy on {dataset} with {activation}: {test_acc:.4f}\")\n",
    "            \n",
    "            # Save test accuracy results\n",
    "            save_test_results(dataset, activation, test_loss, test_acc)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Super graphs saved in super_graphs with clear labels.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define datasets and activation functions\n",
    "datasets = [\"fashion_mnist\", \"cifar10\", \"cifar100\"]\n",
    "\n",
    "# Folder for saved graphs\n",
    "graph_folder = \"saved_graphs\"\n",
    "super_graph_folder = \"super_graphs\"\n",
    "os.makedirs(super_graph_folder, exist_ok=True)\n",
    "\n",
    "# Create super graphs for each dataset\n",
    "for dataset in datasets:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for activation in activation_functions:\n",
    "        graph_path = os.path.join(graph_folder, f\"training_{dataset}_{activation}.png\")\n",
    "        \n",
    "        if os.path.exists(graph_path):\n",
    "            history = np.load(graph_path, allow_pickle=True).item()\n",
    "            plt.plot(history['accuracy'], label=f\"{activation}\", color=activation_colors.get(activation, \"black\"), linewidth=2)\n",
    "            plt.plot(history[\"val_accuracy\"], label=f\"{activation} Val\", color=activation_colors.get(activation, \"black\"), linestyle=\"--\")\n",
    "    # Graph customization\n",
    "    plt.title(f\"Super Graph - {dataset}\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Epochs\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.legend(title=\"Activation Functions\", fontsize=10, title_fontsize=\"12\", loc=\"best\")  # Proper activation labels\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)  # Light grid for readability\n",
    "    \n",
    "    # Save super graph\n",
    "    super_graph_path = os.path.join(super_graph_folder, f\"super_graph_{dataset}.png\")\n",
    "    plt.savefig(super_graph_path, dpi=300)  # High-resolution save\n",
    "    plt.close()\n",
    "\n",
    "print(f\"✅ Super graphs saved in {super_graph_folder} with clear labels.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
